{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactuals and Positional Variables\n",
    "\n",
    "This notebook demonstrates two key concepts for entity binding experiments:\n",
    "\n",
    "1. **Counterfactual datasets** - How to generate counterfactuals by swapping entity groups\n",
    "2. **Positional causal models** - Two different hypotheses about how retrieval works\n",
    "\n",
    "## The Core Question\n",
    "\n",
    "When a language model sees \"Pete loves jam, and Ann loves pie. What does Ann love?\", how does it retrieve the answer?\n",
    "\n",
    "**Hypothesis 1 (Direct)**: The model learns that \"group 1\" (Ann's group) is at a specific position in its representation, and directly retrieves from that position.\n",
    "\n",
    "**Hypothesis 2 (Positional)**: The model searches for \"Ann\" in its stored bindings, finds where Ann appears, then retrieves the associated value from that location.\n",
    "\n",
    "We can test these hypotheses using **counterfactual experiments** where we swap entity groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from causalab.tasks.entity_binding.config import create_sample_love_config\n",
    "from causalab.tasks.entity_binding.causal_models import (\n",
    "    create_direct_causal_model,\n",
    "    create_positional_causal_model,\n",
    ")\n",
    "from causalab.tasks.entity_binding.counterfactual import swap_query_group, random_counterfactual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Two Causal Models\n",
    "\n",
    "Let's start by seeing how the two models work on the same input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created two causal models:\n",
      "  Direct model:     entity_binding_direct_3g_2e\n",
      "  Positional model: entity_binding_positional_3g_2e\n"
     ]
    }
   ],
   "source": [
    "# Create both models\n",
    "config = create_sample_love_config()\n",
    "direct_model = create_direct_causal_model(config)\n",
    "positional_model = create_positional_causal_model(config)\n",
    "\n",
    "print(\"Created two causal models:\")\n",
    "print(f\"  Direct model:     {direct_model.id}\")\n",
    "print(f\"  Positional model: {positional_model.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input configuration:\n",
      "  Entities: g0=(Pete, jam), g1=(Ann, pie), g2=(Bob, cake)\n",
      "  Query: group 1, entity 0\n",
      "  Answer: entity at group 1, position 1\n"
     ]
    }
   ],
   "source": [
    "# Create a specific example\n",
    "input_sample = {\n",
    "    \"entity_g0_e0\": \"Pete\",\n",
    "    \"entity_g0_e1\": \"jam\",\n",
    "    \"entity_g1_e0\": \"Ann\",\n",
    "    \"entity_g1_e1\": \"pie\",\n",
    "    \"entity_g2_e0\": \"Bob\",\n",
    "    \"entity_g2_e1\": \"cake\",\n",
    "    \"query_group\": 1,\n",
    "    \"query_indices\": (0,),\n",
    "    \"answer_index\": 1,\n",
    "    \"active_groups\": 3,\n",
    "    \"entities_per_group\": 2,\n",
    "}\n",
    "\n",
    "print(\"Input configuration:\")\n",
    "print(\"  Entities: g0=(Pete, jam), g1=(Ann, pie), g2=(Bob, cake)\")\n",
    "print(\n",
    "    f\"  Query: group {input_sample['query_group']}, entity {input_sample['query_indices'][0]}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Answer: entity at group {input_sample['query_group']}, position {input_sample['answer_index']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt generated:\n",
      "  Pete loves jam, Ann loves pie, and Bob loves cake. What does Ann love?\n",
      "\n",
      "Direct model (index-based):\n",
      "  Mechanism: Uses query_group=1 directly\n",
      "  Retrieves: entity_g1_e1 = pie\n",
      "  Answer: pie\n",
      "\n",
      "Positional model (search-based):\n",
      "  Step 1: Extract query entity from g1_e0 = ('Ann',)\n",
      "  Step 2: Search for ('Ann',) at position e0 across groups\n",
      "  Step 3: Found at group 1\n",
      "  Step 4: Retrieve from g1_e1\n",
      "  Answer: pie\n",
      "\n",
      "On this input, both models agree: True\n"
     ]
    }
   ],
   "source": [
    "# Run both models\n",
    "direct_output = direct_model.run_forward(input_sample)\n",
    "positional_output = positional_model.run_forward(input_sample)\n",
    "\n",
    "print(\"\\nPrompt generated:\")\n",
    "print(f\"  {direct_output['raw_input']}\")\n",
    "print()\n",
    "\n",
    "print(\"Direct model (index-based):\")\n",
    "print(f\"  Mechanism: Uses query_group={input_sample['query_group']} directly\")\n",
    "print(f\"  Retrieves: entity_g1_e1 = {input_sample['entity_g1_e1']}\")\n",
    "print(f\"  Answer: {direct_output['raw_output']}\")\n",
    "print()\n",
    "\n",
    "print(\"Positional model (search-based):\")\n",
    "print(\n",
    "    f\"  Step 1: Extract query entity from g1_e0 = {positional_output['query_entity']}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Step 2: Search for {positional_output['query_entity']} at position e0 across groups\"\n",
    ")\n",
    "print(f\"  Step 3: Found at group {positional_output['positional_query_group']}\")\n",
    "print(\n",
    "    f\"  Step 4: Retrieve from g{positional_output['positional_query_group']}_e{input_sample['answer_index']}\"\n",
    ")\n",
    "print(f\"  Answer: {positional_output['raw_output']}\")\n",
    "print()\n",
    "\n",
    "print(\n",
    "    \"On this input, both models agree:\",\n",
    "    direct_output[\"raw_output\"] == positional_output[\"raw_output\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: What Happens When We Swap Groups?\n",
    "\n",
    "Now let's swap entity groups and see how the models behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After swapping groups 1 and 2:\n",
      "  Entities: g0=(Pete, jam), g1=(Bob, cake), g2=(Ann, pie)\n",
      "  Query: still group 1, entity 0\n",
      "  Now querying Bob (who moved from g2 to g1)\n"
     ]
    }
   ],
   "source": [
    "# Swap groups 1 and 2\n",
    "swapped_sample = input_sample.copy()\n",
    "swapped_sample[\"entity_g1_e0\"] = \"Bob\"  # g1 gets g2's entities\n",
    "swapped_sample[\"entity_g1_e1\"] = \"cake\"\n",
    "swapped_sample[\"entity_g2_e0\"] = \"Ann\"  # g2 gets g1's entities\n",
    "swapped_sample[\"entity_g2_e1\"] = \"pie\"\n",
    "# query_group STAYS 1\n",
    "\n",
    "print(\"After swapping groups 1 and 2:\")\n",
    "print(\"  Entities: g0=(Pete, jam), g1=(Bob, cake), g2=(Ann, pie)\")\n",
    "print(\n",
    "    f\"  Query: still group {swapped_sample['query_group']}, entity {swapped_sample['query_indices'][0]}\"\n",
    ")\n",
    "print(\"  Now querying Bob (who moved from g2 to g1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt generated:\n",
      "  Pete loves jam, Bob loves cake, and Ann loves pie. What does Bob love?\n",
      "\n",
      "Direct model:\n",
      "  Still uses query_group=1 directly\n",
      "  Retrieves: entity_g1_e1 = cake\n",
      "  Answer: cake\n",
      "\n",
      "Positional model:\n",
      "  Extracts query entity from g1_e0: ('Bob',)\n",
      "  Searches for ('Bob',) at position e0\n",
      "  Found at group: 1\n",
      "  Retrieves from g1_e1\n",
      "  Answer: cake\n",
      "\n",
      "After swap, both models still agree: True\n",
      "(Because Bob is at g1 in the swapped configuration)\n"
     ]
    }
   ],
   "source": [
    "# Run both models on swapped input\n",
    "direct_swapped = direct_model.run_forward(swapped_sample)\n",
    "positional_swapped = positional_model.run_forward(swapped_sample)\n",
    "\n",
    "print(\"Prompt generated:\")\n",
    "print(f\"  {direct_swapped['raw_input']}\")\n",
    "print()\n",
    "\n",
    "print(\"Direct model:\")\n",
    "print(\"  Still uses query_group=1 directly\")\n",
    "print(f\"  Retrieves: entity_g1_e1 = {swapped_sample['entity_g1_e1']}\")\n",
    "print(f\"  Answer: {direct_swapped['raw_output']}\")\n",
    "print()\n",
    "\n",
    "print(\"Positional model:\")\n",
    "print(f\"  Extracts query entity from g1_e0: {positional_swapped['query_entity']}\")\n",
    "print(f\"  Searches for {positional_swapped['query_entity']} at position e0\")\n",
    "print(f\"  Found at group: {positional_swapped['positional_query_group']}\")\n",
    "print(f\"  Retrieves from g{positional_swapped['positional_query_group']}_e1\")\n",
    "print(f\"  Answer: {positional_swapped['raw_output']}\")\n",
    "print()\n",
    "\n",
    "print(\n",
    "    \"After swap, both models still agree:\",\n",
    "    direct_swapped[\"raw_output\"] == positional_swapped[\"raw_output\"],\n",
    ")\n",
    "print(\"(Because Bob is at g1 in the swapped configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Do They Still Agree?\n",
    "\n",
    "On **behavioral** (symbolic) models, both approaches give the same answer because we're just computing what the answer SHOULD be.\n",
    "\n",
    "The difference appears when testing **neural networks** with interventions:\n",
    "\n",
    "- If we intervene on the neural representation of \"group 1\" and change it to represent Bob instead of Ann:\n",
    "  - **Direct model prediction**: Should answer based on what's now in group 1 (cake)\n",
    "  - **Positional model prediction**: Should search for the entity mentioned in the question, might not find it correctly\n",
    "\n",
    "The models represent different hypotheses we're testing about the neural network's mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Generating Counterfactual Datasets\n",
    "\n",
    "For intervention experiments, we need pairs of (input, counterfactual) to test the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual pair generated by swap_query_group:\n",
      "\n",
      "INPUT:\n",
      "  Prompt: Bob loves jam, and Tim loves bread. Who loves jam?\n",
      "  Query group: 0\n",
      "\n",
      "COUNTERFACTUAL:\n",
      "  Prompt: Tim loves bread, and Bob loves jam. Who loves jam?\n",
      "  Query group: 1 (same position!)\n"
     ]
    }
   ],
   "source": [
    "# Generate a counterfactual using swap_query_group\n",
    "example = swap_query_group(config)\n",
    "\n",
    "input_ex = example[\"input\"]\n",
    "counter_ex = example[\"counterfactual_inputs\"][0]\n",
    "\n",
    "print(\"Counterfactual pair generated by swap_query_group:\")\n",
    "print()\n",
    "print(\"INPUT:\")\n",
    "print(f\"  Prompt: {input_ex['raw_input']}\")\n",
    "print(f\"  Query group: {input_ex['query_group']}\")\n",
    "print()\n",
    "print(\"COUNTERFACTUAL:\")\n",
    "print(f\"  Prompt: {counter_ex['raw_input']}\")\n",
    "print(f\"  Query group: {counter_ex['query_group']} (same position!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What changed between input and counterfactual:\n",
      "\n",
      "Entities in query group 0:\n",
      "  Position e0:\n",
      "    Input:          Bob\n",
      "    Counterfactual: Tim <-- CHANGED\n",
      "  Position e1:\n",
      "    Input:          jam\n",
      "    Counterfactual: bread <-- CHANGED\n"
     ]
    }
   ],
   "source": [
    "# Show what changed\n",
    "print(\"\\nWhat changed between input and counterfactual:\\n\")\n",
    "\n",
    "query_group = input_ex[\"query_group\"]\n",
    "print(f\"Entities in query group {query_group}:\")\n",
    "for e in range(config.max_entities_per_group):\n",
    "    key = f\"entity_g{query_group}_e{e}\"\n",
    "    input_val = input_ex.get(key)\n",
    "    counter_val = counter_ex.get(key)\n",
    "    changed = \"<-- CHANGED\" if input_val != counter_val else \"\"\n",
    "    print(f\"  Position e{e}:\")\n",
    "    print(f\"    Input:          {input_val}\")\n",
    "    print(f\"    Counterfactual: {counter_val} {changed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Interchange Interventions\n",
    "\n",
    "Like the MCQA example, we can perform interchange interventions to test causal variable localization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input:\n",
      "  Entity at g1_e0: Ann\n",
      "  query_entity: ('Ann',)\n",
      "  positional_query_group: 1\n",
      "  raw_output: pie\n",
      "\n",
      "Counterfactual input:\n",
      "  Entity at g1_e0: Ann\n",
      "  query_entity: ('Pete',)\n",
      "  positional_query_group: 2\n",
      "  raw_output: tea\n",
      "\n",
      "Intervened output (using query_entity from counterfactual):\n",
      "  query_entity: ('Pete',)\n",
      "  positional_query_group: 0\n",
      "  raw_output: jam\n"
     ]
    }
   ],
   "source": [
    "# Perform interchange intervention on query_entity\n",
    "# Use the same input_sample and create a counterfactual\n",
    "\n",
    "counterfactual_sample = {\n",
    "    \"entity_g0_e0\": \"Tim\",\n",
    "    \"entity_g0_e1\": \"soup\",\n",
    "    \"entity_g1_e0\": \"Ann\",  # Different entity at same position\n",
    "    \"entity_g1_e1\": \"bread\",\n",
    "    \"entity_g2_e0\": \"Pete\",\n",
    "    \"entity_g2_e1\": \"tea\",\n",
    "    \"query_group\": 2,\n",
    "    \"query_indices\": (0,),\n",
    "    \"answer_index\": 1,\n",
    "    \"active_groups\": 3,\n",
    "    \"entities_per_group\": 2,\n",
    "}\n",
    "\n",
    "print(\"Original input:\")\n",
    "print(f\"  Entity at g1_e0: {input_sample['entity_g1_e0']}\")\n",
    "original_output = positional_model.run_forward(input_sample)\n",
    "print(f\"  query_entity: {original_output['query_entity']}\")\n",
    "print(f\"  positional_query_group: {original_output['positional_query_group']}\")\n",
    "print(f\"  raw_output: {original_output['raw_output']}\")\n",
    "print()\n",
    "\n",
    "print(\"Counterfactual input:\")\n",
    "print(f\"  Entity at g1_e0: {counterfactual_sample['entity_g1_e0']}\")\n",
    "counter_output = positional_model.run_forward(counterfactual_sample)\n",
    "print(f\"  query_entity: {counter_output['query_entity']}\")\n",
    "print(f\"  positional_query_group: {counter_output['positional_query_group']}\")\n",
    "print(f\"  raw_output: {counter_output['raw_output']}\")\n",
    "print()\n",
    "\n",
    "# Interchange intervention on query_entity\n",
    "intervened = positional_model.run_interchange(\n",
    "    input_sample, {\"query_entity\": counterfactual_sample}\n",
    ")\n",
    "\n",
    "print(\"Intervened output (using query_entity from counterfactual):\")\n",
    "print(f\"  query_entity: {intervened['query_entity']}\")\n",
    "print(f\"  positional_query_group: {intervened['positional_query_group']}\")\n",
    "print(f\"  raw_output: {intervened['raw_output']}\")\n",
    "intervened = positional_model.run_interchange(\n",
    "    input_sample, {\"positional_query_group\": counterfactual_sample}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Generate Counterfactual Dataset\n",
    "\n",
    "Now let's generate a full dataset of counterfactual pairs for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 64 counterfactual pairs\n",
      "  Input:  Kate loves tea, Ann loves pie, and Bob loves cake. What does Kate love?\n",
      "  Counter: Ann loves pie, Kate loves tea, and Bob loves cake. What does Kate love?\n"
     ]
    }
   ],
   "source": [
    "from causalab.causal.counterfactual_dataset import CounterfactualDataset\n",
    "\n",
    "config.num_groups = 3\n",
    "\n",
    "# Generate 64 counterfactual pairs using swap_query_group\n",
    "swap_dataset = CounterfactualDataset.from_sampler(64, lambda: swap_query_group(config))\n",
    "\n",
    "print(f\"Generated {len(swap_dataset)} counterfactual pairs\")\n",
    "print(f\"  Input:  {swap_dataset[0]['input']['raw_input']}\")\n",
    "print(f\"  Counter: {swap_dataset[0]['counterfactual_inputs'][0]['raw_input']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Testing Distinguishability\n",
    "\n",
    "We can test if this counterfactual dataset can distinguish between different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we distinguish query_entity from raw_output?\n",
      "Can distinguish between ['query_entity'] and ['positional_query_group']: 64 out of 64 examples\n",
      "Proportion of distinguishable examples: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'proportion': 1.0, 'count': 64}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if we can distinguish query_entity from raw_output\n",
    "print(\"Can we distinguish query_entity from raw_output?\")\n",
    "positional_model.can_distinguish_with_dataset(\n",
    "    swap_dataset, [\"query_entity\"], [\"positional_query_group\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we distinguish positional_query_group from raw_output?\n",
      "Can distinguish between ['positional_query_group'] and ['raw_output']: 64 out of 64 examples\n",
      "Proportion of distinguishable examples: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'proportion': 1.0, 'count': 64}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if we can distinguish positional_query_group from raw_output\n",
    "print(\"Can we distinguish positional_query_group from raw_output?\")\n",
    "positional_model.can_distinguish_with_dataset(\n",
    "    swap_dataset, [\"positional_query_group\"], [\"raw_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we distinguish query_entity from no intervention?\n",
      "Can distinguish between ['positional_query_group'] and None: 64 out of 64 examples\n",
      "Proportion of distinguishable examples: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'proportion': 1.0, 'count': 64}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if we can distinguish query_entity from no intervention\n",
    "print(\"Can we distinguish query_entity from no intervention?\")\n",
    "positional_model.can_distinguish_with_dataset(\n",
    "    swap_dataset, [\"positional_query_group\"], None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Random Counterfactuals (Baseline)\n",
    "\n",
    "Let's compare with random counterfactuals to see the difference in discrimination power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 64 random counterfactual pairs\n",
      "Example pair (completely independent):\n",
      "  Input:  Tim loves cake, and Sue loves bread. What does Sue love?\n",
      "  Counter: Sue loves soup, and Bob loves bread. What does Bob love?\n"
     ]
    }
   ],
   "source": [
    "# Generate random counterfactual dataset\n",
    "random_dataset = CounterfactualDataset.from_sampler(\n",
    "    64, lambda: random_counterfactual(config)\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(random_dataset)} random counterfactual pairs\")\n",
    "print(\"Example pair (completely independent):\")\n",
    "print(f\"  Input:  {random_dataset[0]['input']['raw_input']}\")\n",
    "print(f\"  Counter: {random_dataset[0]['counterfactual_inputs'][0]['raw_input']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With random counterfactuals:\n",
      "query_entity vs raw_output:\n",
      "Can distinguish between ['query_entity'] and ['positional_query_group']: 56 out of 64 examples\n",
      "Proportion of distinguishable examples: 0.88\n",
      "positional_query_group vs raw_output:\n",
      "Can distinguish between ['positional_query_group'] and ['raw_output']: 58 out of 64 examples\n",
      "Proportion of distinguishable examples: 0.91\n",
      "query_entity vs no intervention:\n",
      "Can distinguish between ['query_entity'] and None: 60 out of 64 examples\n",
      "Proportion of distinguishable examples: 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'proportion': 0.9375, 'count': 60}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test distinguishability with random counterfactuals\n",
    "print(\"With random counterfactuals:\")\n",
    "print(\"query_entity vs raw_output:\")\n",
    "positional_model.can_distinguish_with_dataset(\n",
    "    random_dataset, [\"query_entity\"], [\"positional_query_group\"]\n",
    ")\n",
    "print(\"positional_query_group vs raw_output:\")\n",
    "positional_model.can_distinguish_with_dataset(\n",
    "    random_dataset, [\"positional_query_group\"], [\"raw_output\"]\n",
    ")\n",
    "print(\"query_entity vs no intervention:\")\n",
    "positional_model.can_distinguish_with_dataset(random_dataset, [\"query_entity\"], None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-abstraction-5z8AXW-K-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Position Functions for Entity Binding\n",
    "\n",
    "This notebook demonstrates the **template-aware token position system** for entity binding tasks. Token positions are crucial for causal interventions - they tell us **WHERE** in the transformer to intervene to test causal hypotheses.\n",
    "\n",
    "## How It Works: The Mega Template\n",
    "\n",
    "The system uses a **mega template** with unique variable names for each entity position:\n",
    "- Statement entities: `{g0_e0}`, `{g0_e1}`, `{g1_e0}`, `{g1_e1}`, ...\n",
    "- Question entities: `{person}`, `{query_entity}`, `{food}`, ...\n",
    "\n",
    "This means each entity has a **unique variable name** in the template, eliminating ambiguity even when the same entity value appears multiple times.\n",
    "\n",
    "Example mega template:\n",
    "```\n",
    "\"{g0_e0} loves {g0_e1} and {g1_e0} loves {g1_e1}. What does {person} love?\"\n",
    "```\n",
    "\n",
    "Filled with values:\n",
    "```\n",
    "\"Pete loves jam and Ann loves pie. What does Pete love?\"\n",
    "```\n",
    "\n",
    "Even though \"Pete\" appears twice, we can distinguish them:\n",
    "- `g0_e0` = Pete in the statement\n",
    "- `person` = Pete in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from causalab.tasks.entity_binding.config import (\n",
    "    create_sample_love_config,\n",
    "    create_sample_action_config,\n",
    ")\n",
    "from causalab.tasks.entity_binding.causal_models import (\n",
    "    create_positional_entity_causal_model,\n",
    "    sample_valid_entity_binding_input,\n",
    ")\n",
    "from causalab.tasks.entity_binding.token_positions import (\n",
    "    get_entity_token_positions,\n",
    "    get_question_entity_token_positions,\n",
    "    get_statement_entity_token_positions,\n",
    ")\n",
    "from causalab.neural.pipeline import LMPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Ambiguity Problem (Why We Need Structure)\n",
    "\n",
    "Let's start by demonstrating the problem that the new system solves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load language model and create causal model\n",
    "print(\"Loading GPT-2 model...\")\n",
    "pipeline = LMPipeline(\"gpt2\")\n",
    "config = create_sample_love_config()\n",
    "model = create_positional_entity_causal_model(config)\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Pete loves jam and Ann loves pie. What does Pete love?\n",
      "Answer:\n",
      "\n",
      "Note: 'Pete' appears TWICE in this prompt:\n",
      "  1. In the statement: 'Pete loves jam'\n",
      "  2. In the question: 'What does Pete love?'\n",
      "\n",
      "Which 'Pete' do we want to intervene on?\n"
     ]
    }
   ],
   "source": [
    "# Create example where \"Pete\" appears in both statement and question\n",
    "# Use the causal model to generate a properly structured trace\n",
    "trace = model.new_trace({\n",
    "    \"entity_g0_e0\": \"Pete\",\n",
    "    \"entity_g0_e1\": \"jam\",\n",
    "    \"entity_g1_e0\": \"Ann\",\n",
    "    \"entity_g1_e1\": \"pie\",\n",
    "    \"entity_g2_e0\": None,\n",
    "    \"entity_g2_e1\": None,\n",
    "    \"query_group\": 0,\n",
    "    \"query_indices\": (0,),\n",
    "    \"answer_index\": 1,\n",
    "    \"active_groups\": 2,\n",
    "    \"entities_per_group\": 2,\n",
    "    # Query entity variables (from the query group)\n",
    "    \"query_e0\": \"Pete\",\n",
    "    \"query_e1\": \"jam\",\n",
    "    \"statement_template\": config.statement_template,\n",
    "})\n",
    "\n",
    "print(\"Prompt:\", trace[\"raw_input\"])\n",
    "print(\"\\nNote: 'Pete' appears TWICE in this prompt:\")\n",
    "print(\"  1. In the statement: 'Pete loves jam'\")\n",
    "print(\"  2. In the question: 'What does Pete love?'\")\n",
    "print(\"\\nWhich 'Pete' do we want to intervene on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full tokenization:\n",
      "Total tokens: 29\n",
      "\n",
      "Token  0: 'We'                \n",
      "Token  1: ' will'             \n",
      "Token  2: ' ask'              \n",
      "Token  3: ' a'                \n",
      "Token  4: ' question'         \n",
      "Token  5: ' about'            \n",
      "Token  6: ' the'              \n",
      "Token  7: ' following'        \n",
      "Token  8: ' sentences'        \n",
      "Token  9: '.'                 \n",
      "Token 10: '\\n'                \n",
      "Token 11: '\\n'                \n",
      "Token 12: 'P'                  <-- FIRST Pete (statement)\n",
      "Token 13: 'ete'                <-- FIRST Pete (statement)\n",
      "Token 14: ' loves'            \n",
      "Token 15: ' jam'              \n",
      "Token 16: ' and'              \n",
      "Token 17: ' Ann'              \n",
      "Token 18: ' loves'            \n",
      "Token 19: ' pie'              \n",
      "Token 20: '.'                 \n",
      "Token 21: ' What'             \n",
      "Token 22: ' does'             \n",
      "Token 23: ' Pete'              <-- SECOND Pete (question)\n",
      "Token 24: ' love'             \n",
      "Token 25: '?'                 \n",
      "Token 26: '\\n'                \n",
      "Token 27: 'Answer'            \n",
      "Token 28: ':'                 \n"
     ]
    }
   ],
   "source": [
    "# Show full tokenization\n",
    "# pipeline.load() expects a list of CausalTrace objects\n",
    "tokens = pipeline.load([trace])[\"input_ids\"][0].tolist()\n",
    "print(\"Full tokenization:\")\n",
    "print(f\"Total tokens: {len(tokens)}\\n\")\n",
    "\n",
    "for i, token_id in enumerate(tokens):\n",
    "    token_str = pipeline.tokenizer.decode([token_id])\n",
    "    if i in [12, 13]:\n",
    "        marker = \" <-- FIRST Pete (statement)\"\n",
    "    elif \"Pete\" in token_str and i > 5:\n",
    "        marker = \" <-- SECOND Pete (question)\"\n",
    "    else:\n",
    "        marker = \"\"\n",
    "    print(f\"Token {i:2d}: {repr(token_str):20s}{marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Mega Template System\n",
    "\n",
    "Let's see how the mega template creates unique variable names for each entity position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mega Template:\n",
      "  We will ask a question about the following sentences.\n",
      "\n",
      "{g0_e0} loves {g0_e1} and {g1_e0} loves {g1_e1}. What does {person} love?\n",
      "Answer:\n",
      "\n",
      "Variable names in template:\n",
      "  Statement: g0_e0 (Pete), g0_e1 (jam), g1_e0 (Ann), g1_e1 (pie)\n",
      "  Question: person (Pete), query_entity (Pete)\n",
      "\n",
      "Each position has a UNIQUE variable name!\n"
     ]
    }
   ],
   "source": [
    "# Show the mega template for this sample\n",
    "mega_template = config.build_mega_template(\n",
    "    active_groups=trace[\"active_groups\"],\n",
    "    query_indices=trace[\"query_indices\"],\n",
    "    answer_index=trace[\"answer_index\"],\n",
    ")\n",
    "\n",
    "print(\"Mega Template:\")\n",
    "print(f\"  {mega_template}\")\n",
    "print(\"\\nVariable names in template:\")\n",
    "print(\"  Statement: g0_e0 (Pete), g0_e1 (jam), g1_e0 (Ann), g1_e1 (pie)\")\n",
    "print(\"  Question: person (Pete), query_entity (Pete)\")\n",
    "print(\"\\nEach position has a UNIQUE variable name!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Getting Token Positions\n",
    "\n",
    "Now let's use the token position functions to find where each entity is in the tokenized prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pete in STATEMENT (g0_e0): tokens [12, 13]\n",
      "Pete in QUESTION (person): tokens [23]\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHT: Same entity value, different token positions!\n",
      "======================================================================\n",
      "Statement Pete: tokens [12, 13]\n",
      "Question Pete:  tokens [23]\n"
     ]
    }
   ],
   "source": [
    "# Get Pete from the STATEMENT (group 0, entity 0)\n",
    "pete_statement = get_entity_token_positions(\n",
    "    trace, pipeline, config, group_idx=0, entity_idx=0\n",
    ")\n",
    "print(f\"Pete in STATEMENT (g0_e0): tokens {pete_statement}\")\n",
    "\n",
    "# Get Pete from the QUESTION (using role name)\n",
    "pete_question = get_question_entity_token_positions(\n",
    "    trace, pipeline, config, role_name=\"person\"\n",
    ")\n",
    "print(f\"Pete in QUESTION (person): tokens {pete_question}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHT: Same entity value, different token positions!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Statement Pete: tokens {pete_statement}\")\n",
    "print(f\"Question Pete:  tokens {pete_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visual Verification\n",
    "\n",
    "Let's visualize which tokens are selected for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-by-token breakdown:\n",
      "\n",
      "Token  0: 'We'                \n",
      "Token  1: ' will'             \n",
      "Token  2: ' ask'              \n",
      "Token  3: ' a'                \n",
      "Token  4: ' question'         \n",
      "Token  5: ' about'            \n",
      "Token  6: ' the'              \n",
      "Token  7: ' following'        \n",
      "Token  8: ' sentences'        \n",
      "Token  9: '.'                 \n",
      "Token 10: '\\n'                \n",
      "Token 11: '\\n'                \n",
      "Token 12: 'P'                  <-- g0_e0 (Pete)\n",
      "Token 13: 'ete'                <-- g0_e0 (Pete)\n",
      "Token 14: ' loves'            \n",
      "Token 15: ' jam'               <-- g0_e1 (jam)\n",
      "Token 16: ' and'              \n",
      "Token 17: ' Ann'               <-- g1_e0 (Ann)\n",
      "Token 18: ' loves'            \n",
      "Token 19: ' pie'               <-- g1_e1 (pie)\n",
      "Token 20: '.'                 \n",
      "Token 21: ' What'             \n",
      "Token 22: ' does'             \n",
      "Token 23: ' Pete'              <-- question (Pete)\n",
      "Token 24: ' love'             \n",
      "Token 25: '?'                 \n",
      "Token 26: '\\n'                \n",
      "Token 27: 'Answer'            \n",
      "Token 28: ':'                 \n"
     ]
    }
   ],
   "source": [
    "# Show which tokens correspond to which entities\n",
    "print(\"Token-by-token breakdown:\\n\")\n",
    "\n",
    "# Get all entity positions\n",
    "entity_positions = {\n",
    "    \"g0_e0 (Pete)\": get_entity_token_positions(trace, pipeline, config, 0, 0),\n",
    "    \"g0_e1 (jam)\": get_entity_token_positions(trace, pipeline, config, 0, 1),\n",
    "    \"g1_e0 (Ann)\": get_entity_token_positions(trace, pipeline, config, 1, 0),\n",
    "    \"g1_e1 (pie)\": get_entity_token_positions(trace, pipeline, config, 1, 1),\n",
    "    \"question (Pete)\": get_question_entity_token_positions(trace, pipeline, config, role_name=\"person\"),\n",
    "}\n",
    "\n",
    "for i, token_id in enumerate(tokens):\n",
    "    token_str = pipeline.tokenizer.decode([token_id])\n",
    "    markers = []\n",
    "    for name, positions in entity_positions.items():\n",
    "        if i in positions:\n",
    "            markers.append(name)\n",
    "    marker_str = \" <-- \" + \", \".join(markers) if markers else \"\"\n",
    "    print(f\"Token {i:2d}: {repr(token_str):20s}{marker_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: All Statement Entities\n",
    "\n",
    "Let's find token positions for all entities in the statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All statement entities:\n",
      "\n",
      "  g0_e0 (person): 'Pete      ' -> tokens [12, 13]\n",
      "  g0_e1 (food  ): 'jam       ' -> tokens [15]\n",
      "  g1_e0 (person): 'Ann       ' -> tokens [17]\n",
      "  g1_e1 (food  ): 'pie       ' -> tokens [19]\n",
      "\n",
      "Question entity:\n",
      "  person: 'Pete' -> tokens [23]\n"
     ]
    }
   ],
   "source": [
    "# Find all entities in the prompt\n",
    "print(\"All statement entities:\\n\")\n",
    "\n",
    "for g in range(trace[\"active_groups\"]):\n",
    "    for e in range(trace[\"entities_per_group\"]):\n",
    "        entity_value = trace[f\"entity_g{g}_e{e}\"]\n",
    "        role = config.entity_roles[e]\n",
    "        entity_tokens = get_entity_token_positions(trace, pipeline, config, g, e)\n",
    "        print(f\"  g{g}_e{e} ({role:6}): '{entity_value:10}' -> tokens {entity_tokens}\")\n",
    "\n",
    "print(\"\\nQuestion entity:\")\n",
    "pete_q = get_question_entity_token_positions(trace, pipeline, config, role_name=\"person\")\n",
    "print(f\"  person: '{trace['query_e0']}' -> tokens {pete_q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Multi-Token Entities\n",
    "\n",
    "The system handles multi-token entities and lets you select specific tokens within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-token example:\n",
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Elizabeth loves strawberry jam and Margaret loves apple pie. What does Elizabeth love?\n",
      "Answer:\n",
      "\n",
      "'strawberry jam' all tokens: [14, 15]\n",
      "'strawberry jam' first token (token_idx=0): [14]\n",
      "'strawberry jam' last token (token_idx=-1): [15]\n"
     ]
    }
   ],
   "source": [
    "# Create a sample with multi-token entities using model.new_trace()\n",
    "multi_token_trace = model.new_trace({\n",
    "    \"entity_g0_e0\": \"Elizabeth\",\n",
    "    \"entity_g0_e1\": \"strawberry jam\",\n",
    "    \"entity_g1_e0\": \"Margaret\",\n",
    "    \"entity_g1_e1\": \"apple pie\",\n",
    "    \"entity_g2_e0\": None,\n",
    "    \"entity_g2_e1\": None,\n",
    "    \"query_group\": 0,\n",
    "    \"query_indices\": (0,),\n",
    "    \"answer_index\": 1,\n",
    "    \"active_groups\": 2,\n",
    "    \"entities_per_group\": 2,\n",
    "    \"query_e0\": \"Elizabeth\",\n",
    "    \"query_e1\": \"strawberry jam\",\n",
    "    \"statement_template\": config.statement_template,\n",
    "})\n",
    "\n",
    "print(\"Multi-token example:\")\n",
    "print(f\"Prompt: {multi_token_trace['raw_input']}\\n\")\n",
    "\n",
    "# Get all tokens for 'strawberry jam'\n",
    "all_jam_tokens = get_entity_token_positions(multi_token_trace, pipeline, config, 0, 1)\n",
    "print(f\"'strawberry jam' all tokens: {all_jam_tokens}\")\n",
    "\n",
    "# Get just the first token (token_idx=0)\n",
    "first_token = get_entity_token_positions(multi_token_trace, pipeline, config, 0, 1, token_idx=0)\n",
    "print(f\"'strawberry jam' first token (token_idx=0): {first_token}\")\n",
    "\n",
    "# Get just the last token (token_idx=-1)\n",
    "last_token = get_entity_token_positions(multi_token_trace, pipeline, config, 0, 1, token_idx=-1)\n",
    "print(f\"'strawberry jam' last token (token_idx=-1): {last_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Action Tasks (3-Entity Groups)\n",
    "\n",
    "The system works with more complex templates too - here's a 3-entity example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action task example (person, object, location):\n",
      "Prompt: Kate put key in the box, Sue put pen in the cup, and Lily put watch in the shelf. What was put in the cup?\n",
      "Expected answer: pen\n",
      "\n",
      "Mega template:\n",
      "  {g0_e0} put {g0_e1} in the {g0_e2}, {g1_e0} put {g1_e1} in the {g1_e2}, and {g2_e0} put {g2_e1} in the {g2_e2}. What was put in the {location}?\n"
     ]
    }
   ],
   "source": [
    "# Create action configuration (person, object, location)\n",
    "action_config = create_sample_action_config()\n",
    "action_model = create_positional_entity_causal_model(action_config)\n",
    "\n",
    "# Generate action example using the proper API\n",
    "action_trace = sample_valid_entity_binding_input(action_config, action_model)\n",
    "\n",
    "print(\"Action task example (person, object, location):\")\n",
    "print(f\"Prompt: {action_trace['raw_input']}\")\n",
    "print(f\"Expected answer: {action_trace['raw_output']}\\n\")\n",
    "\n",
    "# Show the mega template\n",
    "action_mega = action_config.build_mega_template(\n",
    "    action_trace[\"active_groups\"],\n",
    "    action_trace[\"query_indices\"],\n",
    "    action_trace[\"answer_index\"],\n",
    ")\n",
    "print(f\"Mega template:\\n  {action_mega}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Using Role Names\n",
    "\n",
    "You can also use role names instead of entity indices for more readable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person in statement (using role_name): [7]\n",
      "Person in statement (using entity_idx=0): [7]\n",
      "\n",
      "Location in question: [27]\n"
     ]
    }
   ],
   "source": [
    "query_group = action_trace[\"query_group\"]\n",
    "# Use role_name instead of entity_idx\n",
    "# For statement entities\n",
    "person_tokens = get_statement_entity_token_positions(\n",
    "    action_trace, pipeline, action_config, \n",
    "    group_idx=query_group, role_name=\"person\"\n",
    ")\n",
    "print(f\"Person in statement (using role_name): {person_tokens}\")\n",
    "\n",
    "# Same thing using entity_idx\n",
    "person_tokens_idx = get_entity_token_positions(\n",
    "    action_trace, pipeline, action_config,\n",
    "    group_idx=query_group, entity_idx=0  # person is entity 0\n",
    ")\n",
    "print(f\"Person in statement (using entity_idx=0): {person_tokens_idx}\")\n",
    "\n",
    "# For question entities - role_name is often more natural\n",
    "query_indices = action_trace[\"query_indices\"]\n",
    "for q_idx in query_indices:\n",
    "    role = action_config.entity_roles[q_idx]\n",
    "    try:\n",
    "        q_tokens = get_question_entity_token_positions(\n",
    "            action_trace, pipeline, action_config, role_name=role\n",
    "        )\n",
    "        print(f\"\\n{role.capitalize()} in question: {q_tokens}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n{role.capitalize()} not in question (expected for some query patterns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Multiple Random Examples\n",
    "\n",
    "Let's see the system work across different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 random examples:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Tim loves pie, Ann loves cake, and Kate loves bread. Who loves bread?\n",
      "Answer:\n",
      "Expected answer: Kate\n",
      "  Query entity in statement (g2_e1): tokens [23]\n",
      "  Query entity in question (food): tokens [27]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Sue loves jam and Pete loves tea. What does Sue love?\n",
      "Answer:\n",
      "Expected answer: jam\n",
      "  Query entity in statement (g0_e0): tokens [12, 13]\n",
      "  Query entity in question (person): tokens [23]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Sue loves jam and Kate loves soup. What does Sue love?\n",
      "Answer:\n",
      "Expected answer: jam\n",
      "  Query entity in statement (g0_e0): tokens [12, 13]\n",
      "  Query entity in question (person): tokens [23]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Bob loves bread, Sue loves cake, and Pete loves tea. Who loves cake?\n",
      "Answer:\n",
      "Expected answer: Sue\n",
      "  Query entity in statement (g1_e1): tokens [18]\n",
      "  Query entity in question (food): tokens [27]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Prompt: We will ask a question about the following sentences.\n",
      "\n",
      "Pete loves bread and Kate loves soup. What does Kate love?\n",
      "Answer:\n",
      "Expected answer: soup\n",
      "  Query entity in statement (g1_e0): tokens [17]\n",
      "  Query entity in question (person): tokens [23]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating 5 random examples:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(5):\n",
    "    # Generate new sample using the causal model\n",
    "    sample_trace = sample_valid_entity_binding_input(config, model)\n",
    "\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    print(f\"Prompt: {sample_trace['raw_input']}\")\n",
    "    print(f\"Expected answer: {sample_trace['raw_output']}\")\n",
    "\n",
    "    # Get query entity from statement and question\n",
    "    query_group = sample_trace[\"query_group\"]\n",
    "    query_idx = sample_trace[\"query_indices\"][0]\n",
    "    query_role = config.entity_roles[query_idx]\n",
    "\n",
    "    statement_tokens = get_entity_token_positions(\n",
    "        sample_trace, pipeline, config, query_group, query_idx\n",
    "    )\n",
    "    print(f\"  Query entity in statement (g{query_group}_e{query_idx}): tokens {statement_tokens}\")\n",
    "\n",
    "    try:\n",
    "        question_tokens = get_question_entity_token_positions(\n",
    "            sample_trace, pipeline, config, role_name=query_role\n",
    "        )\n",
    "        print(f\"  Query entity in question ({query_role}): tokens {question_tokens}\")\n",
    "    except ValueError:\n",
    "        print(f\"  Query entity not in question\")\n",
    "\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Template-Aware Token Positions\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Mega Template**: Combines statement and question templates with unique variable names\n",
    "   - Statement entities: `g0_e0`, `g0_e1`, `g1_e0`, `g1_e1`, ...\n",
    "   - Question entities: `person`, `food`, `query_entity`, ...\n",
    "\n",
    "2. **No Ambiguity**: Each entity position has a unique variable name, even when the same value appears multiple times\n",
    "\n",
    "3. **Flexible Indexing**: Use `token_idx` to select specific tokens within multi-token entities\n",
    "\n",
    "### API Functions:\n",
    "\n",
    "```python\n",
    "# Statement entities (by group and entity index)\n",
    "get_entity_token_positions(sample, pipeline, config, group_idx, entity_idx, token_idx=None)\n",
    "\n",
    "# Statement entities (by role name)\n",
    "get_statement_entity_token_positions(sample, pipeline, config, group_idx, role_name=\"person\")\n",
    "\n",
    "# Question entities (by role name or entity index)\n",
    "get_question_entity_token_positions(sample, pipeline, config, role_name=\"person\")\n",
    "get_question_entity_token_positions(sample, pipeline, config, entity_idx=0)\n",
    "```\n",
    "\n",
    "### For Intervention Experiments:\n",
    "\n",
    "```python\n",
    "# Get entity from statement (for testing representation)\n",
    "statement_tokens = get_entity_token_positions(sample, pipeline, config, group_idx=0, entity_idx=0)\n",
    "\n",
    "# Get entity from question (for testing retrieval)\n",
    "question_tokens = get_question_entity_token_positions(sample, pipeline, config, role_name=\"person\")\n",
    "\n",
    "# Get specific token within multi-token entity\n",
    "last_token = get_entity_token_positions(sample, pipeline, config, 0, 1, token_idx=-1)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalab-internal-tree2 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

#!/usr/bin/env python
"""
Run interchange score grid on entity binding task and generate heatmaps.

This script loads a pre-filtered dataset (generated by generate_and_filter_dataset.py)
and runs interchange interventions to generate heatmaps for causal variables.

Usage:
    # First generate a dataset:
    python -m tasks.entity_binding.experiments.generate_and_filter_dataset \
        --model meta-llama/Llama-3.2-1B-Instruct --config love

    # Then run heatmap experiment:
    python -m tasks.entity_binding.experiments.run_interchange_heatmap \
        --dataset-dir tasks/entity_binding/datasets/swap_query_group_llama_3.2_1b_instruct_love \
        --model meta-llama/Llama-3.2-1B-Instruct
"""

import argparse
from pathlib import Path

import torch

from experiments.interchange_targets import build_residual_stream_targets
from experiments.jobs.interchange_score_grid import run_interchange_score_heatmap
from neural.pipeline import LMPipeline
from neural.token_position_builder import build_token_position_factories

from tasks.entity_binding.experiments.utils import (
    get_task_config,
    get_causal_model,
    get_checker,
)


def create_token_positions(pipeline: LMPipeline, task_config):
    """Create token positions for entity binding task."""
    # Build the mega template for this config
    template = task_config.build_mega_template(
        active_groups=task_config.max_groups,
        query_indices=(0,),
        answer_index=1,
    )

    # Define token position specifications using the declarative system
    token_position_specs = {
        "last_token": {"type": "index", "position": -1},
    }

    # Build token position factories
    factories = build_token_position_factories(token_position_specs, template)

    # Call each factory with the pipeline to create actual TokenPosition objects
    token_positions = {}
    for name, factory in factories.items():
        token_positions[name] = factory(pipeline)

    return token_positions


def run_interchange_heatmap(
    dataset_dir: str,
    model_name: str,
    config_name: str = "love",
    batch_size: int = 32,
    output_dir: str | None = None,
    verbose: bool = True,
):
    """
    Run interchange score heatmap experiment using a pre-filtered dataset.

    Args:
        dataset_dir: Directory containing the filtered dataset (from generate_and_filter_dataset.py)
        model_name: HuggingFace model name (must match model used for dataset generation)
        config_name: Task configuration name ('love' or 'action')
        batch_size: Batch size for inference
        output_dir: Directory to save results (default: {dataset_dir}/heatmap_results)
        verbose: Print progress information
    """
    dataset_path = Path(dataset_dir)

    # Find the filtered dataset
    # The generate script saves to: {output_dir}/{cf_type}/filtered_dataset/
    cf_dataset_path = None
    cf_type = None

    for subdir in dataset_path.iterdir():
        if subdir.is_dir() and (subdir / "filtered_dataset").exists():
            cf_type = subdir.name
            cf_dataset_path = subdir / "filtered_dataset"
            break

    if cf_dataset_path is None:
        raise FileNotFoundError(
            f"Filtered dataset not found in {dataset_path}. "
            f"Run generate_and_filter_dataset.py first."
        )

    if verbose:
        print("=" * 70)
        print("Entity Binding Interchange Heatmap Experiment")
        print("=" * 70)
        print(f"Dataset directory: {dataset_dir}")
        print(f"Counterfactual type: {cf_type}")
        print(f"Model: {model_name}")
        print(f"Config: {config_name}")

    # Setup device
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.bfloat16 if device == "cuda" else torch.float32

    if verbose:
        print(f"Device: {device}")
        print(f"Dtype: {dtype}")

    # Create config and causal model
    task_config = get_task_config(config_name)
    causal_model = get_causal_model(task_config)

    if verbose:
        print(f"\nCausal model: {causal_model.id}")
        print(f"Max groups: {task_config.max_groups}")
        print(f"Entities per group: {task_config.max_entities_per_group}")

    # Load pipeline
    if verbose:
        print(f"\nLoading model: {model_name}")

    pipeline = LMPipeline(
        model_name,
        max_new_tokens=5,
        device=device,
        dtype=dtype,
        max_length=256,
    )
    pipeline.tokenizer.padding_side = "left"

    # Define layers to analyze
    num_layers = pipeline.model.config.num_hidden_layers
    layers = [-1] + list(range(num_layers))  # -1 is embeddings

    if verbose:
        print(f"\nModel has {num_layers} layers")
        print(f"Analyzing layers: -1 (embeddings) through {num_layers - 1}")

    # Create token positions
    token_positions_dict = create_token_positions(pipeline, task_config)
    token_positions = list(token_positions_dict.values())

    if verbose:
        print(f"Token positions: {[tp.id for tp in token_positions]}")

    # Build interchange targets
    targets = build_residual_stream_targets(
        pipeline=pipeline,
        layers=layers,
        token_positions=token_positions,
        mode="one_target_per_unit",
    )

    if verbose:
        print(f"Built {len(targets)} interchange targets")

    # Set output directory
    if output_dir is None:
        output_dir = str(dataset_path / "heatmap_results")

    # Run interchange score heatmap
    target_variables = ["positional_answer", "raw_output"]

    if verbose:
        print(f"\nRunning interchange interventions...")
        print(f"Dataset path: {cf_dataset_path}")
        print(f"Target variables: {target_variables}")
        print(f"Output directory: {output_dir}")

    metric = get_checker()

    result = run_interchange_score_heatmap(
        causal_model=causal_model,
        interchange_targets=targets,
        dataset_path=str(cf_dataset_path),
        pipeline=pipeline,
        target_variables=target_variables,
        batch_size=batch_size,
        output_dir=output_dir,
        metric=metric,
        verbose=verbose,
    )

    if verbose:
        print("\n" + "=" * 70)
        print("Experiment Complete!")
        print("=" * 70)
        print(f"Results saved to: {output_dir}")
        print(f"Heatmaps saved to: {output_dir}/heatmaps/")

    return result


def main():
    parser = argparse.ArgumentParser(
        description="Run entity binding interchange heatmap experiment"
    )
    parser.add_argument(
        "--dataset-dir",
        required=True,
        help="Directory containing filtered dataset (from generate_and_filter_dataset.py)",
    )
    parser.add_argument(
        "--model",
        required=True,
        help="Model name (must match model used for dataset generation)",
    )
    parser.add_argument(
        "--config",
        default="love",
        choices=["love", "action"],
        help="Task configuration name (default: love)",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=32,
        help="Batch size for inference (default: 32)",
    )
    parser.add_argument(
        "--output-dir",
        default=None,
        help="Output directory (default: {dataset_dir}/heatmap_results)",
    )

    args = parser.parse_args()

    run_interchange_heatmap(
        dataset_dir=args.dataset_dir,
        model_name=args.model,
        config_name=args.config,
        batch_size=args.batch_size,
        output_dir=args.output_dir,
    )


if __name__ == "__main__":
    main()

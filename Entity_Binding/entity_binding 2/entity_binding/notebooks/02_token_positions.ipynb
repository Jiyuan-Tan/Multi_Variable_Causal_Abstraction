{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Position Functions for Entity Binding\n",
    "\n",
    "This notebook demonstrates the **template-aware token position system** for entity binding tasks. Token positions are crucial for causal interventions - they tell us **WHERE** in the transformer to intervene to test causal hypotheses.\n",
    "\n",
    "## How It Works: The Mega Template\n",
    "\n",
    "The system uses a **mega template** with unique variable names for each entity position:\n",
    "- Statement entities: `{g0_e0}`, `{g0_e1}`, `{g1_e0}`, `{g1_e1}`, ...\n",
    "- Question entities: `{person}`, `{query_entity}`, `{food}`, ...\n",
    "\n",
    "This means each entity has a **unique variable name** in the template, eliminating ambiguity even when the same entity value appears multiple times.\n",
    "\n",
    "Example mega template:\n",
    "```\n",
    "\"{g0_e0} loves {g0_e1} and {g1_e0} loves {g1_e1}. What does {person} love?\"\n",
    "```\n",
    "\n",
    "Filled with values:\n",
    "```\n",
    "\"Pete loves jam and Ann loves pie. What does Pete love?\"\n",
    "```\n",
    "\n",
    "Even though \"Pete\" appears twice, we can distinguish them:\n",
    "- `g0_e0` = Pete in the statement\n",
    "- `person` = Pete in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tasks.entity_binding.config import (\n",
    "    create_sample_love_config,\n",
    "    create_sample_action_config,\n",
    ")\n",
    "from tasks.entity_binding.causal_models import (\n",
    "    create_positional_entity_causal_model,\n",
    "    sample_valid_entity_binding_input,\n",
    ")\n",
    "from tasks.entity_binding.token_positions import (\n",
    "    get_entity_token_positions,\n",
    "    get_question_entity_token_positions,\n",
    "    get_statement_entity_token_positions,\n",
    ")\n",
    "from neural.pipeline import LMPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Ambiguity Problem (Why We Need Structure)\n",
    "\n",
    "Let's start by demonstrating the problem that the new system solves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model...\n",
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load language model\n",
    "print(\"Loading GPT-2 model...\")\n",
    "pipeline = LMPipeline(\"gpt2\")\n",
    "config = create_sample_love_config()\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Pete loves jam, and Ann loves pie. What does Pete love?\n",
      "\n",
      "Note: 'Pete' appears TWICE in this prompt:\n",
      "  1. In the statement: 'Pete loves jam'\n",
      "  2. In the question: 'What does Pete love?'\n",
      "\n",
      "Which 'Pete' do we want to intervene on?\n"
     ]
    }
   ],
   "source": [
    "# Create example where \"Pete\" appears in both statement and question\n",
    "input_sample = {\n",
    "    \"entity_g0_e0\": \"Pete\",\n",
    "    \"entity_g0_e1\": \"jam\",\n",
    "    \"entity_g1_e0\": \"Ann\",\n",
    "    \"entity_g1_e1\": \"pie\",\n",
    "    \"query_group\": 0,\n",
    "    \"query_indices\": (0,),\n",
    "    \"answer_index\": 1,\n",
    "    \"active_groups\": 2,\n",
    "    \"entities_per_group\": 2,\n",
    "    \"raw_input\": \"Pete loves jam, and Ann loves pie. What does Pete love?\",\n",
    "}\n",
    "\n",
    "print(\"Prompt:\", input_sample[\"raw_input\"])\n",
    "print(\"\\nNote: 'Pete' appears TWICE in this prompt:\")\n",
    "print(\"  1. In the statement: 'Pete loves jam'\")\n",
    "print(\"  2. In the question: 'What does Pete love?'\")\n",
    "print(\"\\nWhich 'Pete' do we want to intervene on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full tokenization:\n",
      "Total tokens: 15\n",
      "\n",
      "Token  0: 'P'                  <-- FIRST Pete (statement)\n",
      "Token  1: 'ete'                <-- FIRST Pete (statement)\n",
      "Token  2: ' loves'            \n",
      "Token  3: ' jam'              \n",
      "Token  4: ','                 \n",
      "Token  5: ' and'              \n",
      "Token  6: ' Ann'              \n",
      "Token  7: ' loves'            \n",
      "Token  8: ' pie'              \n",
      "Token  9: '.'                 \n",
      "Token 10: ' What'             \n",
      "Token 11: ' does'             \n",
      "Token 12: ' Pete'              <-- SECOND Pete (question)\n",
      "Token 13: ' love'             \n",
      "Token 14: '?'                 \n"
     ]
    }
   ],
   "source": [
    "# Show full tokenization\n",
    "tokens = pipeline.load(input_sample)[\"input_ids\"][0].tolist()\n",
    "print(\"Full tokenization:\")\n",
    "print(f\"Total tokens: {len(tokens)}\\n\")\n",
    "\n",
    "for i, token_id in enumerate(tokens):\n",
    "    token_str = pipeline.tokenizer.decode([token_id])\n",
    "    if i in [0, 1]:\n",
    "        marker = \" <-- FIRST Pete (statement)\"\n",
    "    elif i == 12:\n",
    "        marker = \" <-- SECOND Pete (question)\"\n",
    "    else:\n",
    "        marker = \"\"\n",
    "    print(f\"Token {i:2d}: {repr(token_str):20s}{marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Mega Template System\n",
    "\n",
    "Let's see how the mega template creates unique variable names for each entity position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mega Template:\n",
      "  {g0_e0} loves {g0_e1} and {g1_e0} loves {g1_e1}. What does {person} love?\n",
      "\n",
      "Variable names in template:\n",
      "  Statement: g0_e0 (Pete), g0_e1 (jam), g1_e0 (Ann), g1_e1 (pie)\n",
      "  Question: person (Pete), query_entity (Pete)\n",
      "\n",
      "Each position has a UNIQUE variable name!\n"
     ]
    }
   ],
   "source": [
    "# Show the mega template for this sample\n",
    "mega_template = config.build_mega_template(\n",
    "    active_groups=input_sample[\"active_groups\"],\n",
    "    query_indices=input_sample[\"query_indices\"],\n",
    "    answer_index=input_sample[\"answer_index\"],\n",
    ")\n",
    "\n",
    "print(\"Mega Template:\")\n",
    "print(f\"  {mega_template}\")\n",
    "print(\"\\nVariable names in template:\")\n",
    "print(\"  Statement: g0_e0 (Pete), g0_e1 (jam), g1_e0 (Ann), g1_e1 (pie)\")\n",
    "print(\"  Question: person (Pete), query_entity (Pete)\")\n",
    "print(\"\\nEach position has a UNIQUE variable name!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Getting Token Positions\n",
    "\n",
    "Now let's use the token position functions to find where each entity is in the tokenized prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pete in STATEMENT (g0_e0): tokens [0, 1]\n",
      "Pete in QUESTION (person): tokens []\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHT: Same entity value, different token positions!\n",
      "======================================================================\n",
      "Statement Pete: tokens [0, 1]\n",
      "Question Pete:  tokens []\n"
     ]
    }
   ],
   "source": [
    "# Get Pete from the STATEMENT (group 0, entity 0)\n",
    "pete_statement = get_entity_token_positions(\n",
    "    input_sample, pipeline, config, group_idx=0, entity_idx=0\n",
    ")\n",
    "print(f\"Pete in STATEMENT (g0_e0): tokens {pete_statement}\")\n",
    "\n",
    "# Get Pete from the QUESTION (using role name)\n",
    "pete_question = get_question_entity_token_positions(\n",
    "    input_sample, pipeline, config, role_name=\"person\"\n",
    ")\n",
    "print(f\"Pete in QUESTION (person): tokens {pete_question}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHT: Same entity value, different token positions!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Statement Pete: tokens {pete_statement}\")\n",
    "print(f\"Question Pete:  tokens {pete_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visual Verification\n",
    "\n",
    "Let's visualize which tokens are selected for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-by-token breakdown:\n",
      "\n",
      "Token  0: 'P'                  <-- g0_e0 (Pete)\n",
      "Token  1: 'ete'                <-- g0_e0 (Pete)\n",
      "Token  2: ' loves'            \n",
      "Token  3: ' jam'               <-- g0_e1 (jam)\n",
      "Token  4: ','                 \n",
      "Token  5: ' and'               <-- g1_e0 (Ann)\n",
      "Token  6: ' Ann'              \n",
      "Token  7: ' loves'             <-- g1_e1 (pie)\n",
      "Token  8: ' pie'              \n",
      "Token  9: '.'                 \n",
      "Token 10: ' What'             \n",
      "Token 11: ' does'             \n",
      "Token 12: ' Pete'             \n",
      "Token 13: ' love'             \n",
      "Token 14: '?'                 \n"
     ]
    }
   ],
   "source": [
    "# Show which tokens correspond to which entities\n",
    "print(\"Token-by-token breakdown:\\n\")\n",
    "\n",
    "# Get all entity positions\n",
    "entity_positions = {\n",
    "    \"g0_e0 (Pete)\": get_entity_token_positions(input_sample, pipeline, config, 0, 0),\n",
    "    \"g0_e1 (jam)\": get_entity_token_positions(input_sample, pipeline, config, 0, 1),\n",
    "    \"g1_e0 (Ann)\": get_entity_token_positions(input_sample, pipeline, config, 1, 0),\n",
    "    \"g1_e1 (pie)\": get_entity_token_positions(input_sample, pipeline, config, 1, 1),\n",
    "    \"question (Pete)\": get_question_entity_token_positions(input_sample, pipeline, config, role_name=\"person\"),\n",
    "}\n",
    "\n",
    "for i, token_id in enumerate(tokens):\n",
    "    token_str = pipeline.tokenizer.decode([token_id])\n",
    "    markers = []\n",
    "    for name, positions in entity_positions.items():\n",
    "        if i in positions:\n",
    "            markers.append(name)\n",
    "    marker_str = \" <-- \" + \", \".join(markers) if markers else \"\"\n",
    "    print(f\"Token {i:2d}: {repr(token_str):20s}{marker_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: All Statement Entities\n",
    "\n",
    "Let's find token positions for all entities in the statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All statement entities:\n",
      "\n",
      "  g0_e0 (person): 'Pete      ' -> tokens [0, 1]\n",
      "  g0_e1 (food  ): 'jam       ' -> tokens [3]\n",
      "  g1_e0 (person): 'Ann       ' -> tokens [5]\n",
      "  g1_e1 (food  ): 'pie       ' -> tokens [7]\n",
      "\n",
      "Question entity:\n",
      "  person: 'Pete' -> tokens []\n"
     ]
    }
   ],
   "source": [
    "# Find all entities in the prompt\n",
    "print(\"All statement entities:\\n\")\n",
    "\n",
    "for g in range(input_sample[\"active_groups\"]):\n",
    "    for e in range(input_sample[\"entities_per_group\"]):\n",
    "        entity_value = input_sample[f\"entity_g{g}_e{e}\"]\n",
    "        role = config.entity_roles[e]\n",
    "        tokens = get_entity_token_positions(input_sample, pipeline, config, g, e)\n",
    "        print(f\"  g{g}_e{e} ({role:6}): '{entity_value:10}' -> tokens {tokens}\")\n",
    "\n",
    "print(\"\\nQuestion entity:\")\n",
    "pete_q = get_question_entity_token_positions(input_sample, pipeline, config, role_name=\"person\")\n",
    "print(f\"  person: '{input_sample['entity_g0_e0']}' -> tokens {pete_q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Multi-Token Entities\n",
    "\n",
    "The system handles multi-token entities and lets you select specific tokens within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-token example:\n",
      "Prompt: Elizabeth loves strawberry jam and Margaret loves apple pie. What does Pete love?\n",
      "\n",
      "'strawberry jam' all tokens: [2, 3]\n",
      "'strawberry jam' first token (token_idx=0): [2]\n",
      "'strawberry jam' last token (token_idx=-1): [3]\n"
     ]
    }
   ],
   "source": [
    "# Create a sample with multi-token entities\n",
    "model = create_positional_entity_causal_model(config)\n",
    "\n",
    "multi_token_sample = {\n",
    "    \"entity_g0_e0\": \"Elizabeth\",\n",
    "    \"entity_g0_e1\": \"strawberry jam\",\n",
    "    \"entity_g1_e0\": \"Margaret\",\n",
    "    \"entity_g1_e1\": \"apple pie\",\n",
    "    \"query_group\": 0,\n",
    "    \"query_indices\": (0,),\n",
    "    \"answer_index\": 1,\n",
    "    \"active_groups\": 2,\n",
    "    \"entities_per_group\": 2,\n",
    "}\n",
    "output = model.run_forward(multi_token_sample)\n",
    "multi_token_sample[\"raw_input\"] = output[\"raw_input\"]\n",
    "\n",
    "print(\"Multi-token example:\")\n",
    "print(f\"Prompt: {multi_token_sample['raw_input']}\\n\")\n",
    "\n",
    "# Get all tokens for 'strawberry jam'\n",
    "all_jam_tokens = get_entity_token_positions(multi_token_sample, pipeline, config, 0, 1)\n",
    "print(f\"'strawberry jam' all tokens: {all_jam_tokens}\")\n",
    "\n",
    "# Get just the first token (token_idx=0)\n",
    "first_token = get_entity_token_positions(multi_token_sample, pipeline, config, 0, 1, token_idx=0)\n",
    "print(f\"'strawberry jam' first token (token_idx=0): {first_token}\")\n",
    "\n",
    "# Get just the last token (token_idx=-1)\n",
    "last_token = get_entity_token_positions(multi_token_sample, pipeline, config, 0, 1, token_idx=-1)\n",
    "print(f\"'strawberry jam' last token (token_idx=-1): {last_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Action Tasks (3-Entity Groups)\n",
    "\n",
    "The system works with more complex templates too - here's a 3-entity example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action task example (person, object, location):\n",
      "Prompt: Ann put book in the pocket, Tim put watch in the bag, and Sue put jam in the box. Who put something in the bag?\n",
      "Expected answer: Tim\n",
      "\n",
      "Mega template:\n",
      "  {g0_e0} put {g0_e1} in the {g0_e2}, {g1_e0} put {g1_e1} in the {g1_e2}, and {g2_e0} put {g2_e1} in the {g2_e2}. Who put something in the {location}?\n"
     ]
    }
   ],
   "source": [
    "# Create action configuration (person, object, location)\n",
    "action_config = create_sample_action_config()\n",
    "action_model = create_positional_entity_causal_model(action_config)\n",
    "\n",
    "# Generate action example\n",
    "action_sample = sample_valid_entity_binding_input(action_config)\n",
    "action_output = action_model.run_forward(action_sample)\n",
    "action_sample[\"raw_input\"] = action_output[\"raw_input\"]\n",
    "\n",
    "print(\"Action task example (person, object, location):\")\n",
    "print(f\"Prompt: {action_sample['raw_input']}\")\n",
    "print(f\"Expected answer: {action_output['raw_output']}\\n\")\n",
    "\n",
    "# Show the mega template\n",
    "action_mega = action_config.build_mega_template(\n",
    "    action_sample[\"active_groups\"],\n",
    "    action_sample[\"query_indices\"],\n",
    "    action_sample[\"answer_index\"],\n",
    ")\n",
    "print(f\"Mega template:\\n  {action_mega}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Using Role Names\n",
    "\n",
    "You can also use role names instead of entity indices for more readable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person in statement (using role_name): [7]\n",
      "Person in statement (using entity_idx=0): [7]\n",
      "\n",
      "Location in question: [27]\n"
     ]
    }
   ],
   "source": [
    "query_group = action_sample[\"query_group\"]\n",
    "# Use role_name instead of entity_idx\n",
    "# For statement entities\n",
    "person_tokens = get_statement_entity_token_positions(\n",
    "    action_sample, pipeline, action_config, \n",
    "    group_idx=query_group, role_name=\"person\"\n",
    ")\n",
    "print(f\"Person in statement (using role_name): {person_tokens}\")\n",
    "\n",
    "# Same thing using entity_idx\n",
    "person_tokens_idx = get_entity_token_positions(\n",
    "    action_sample, pipeline, action_config,\n",
    "    group_idx=query_group, entity_idx=0  # person is entity 0\n",
    ")\n",
    "print(f\"Person in statement (using entity_idx=0): {person_tokens_idx}\")\n",
    "\n",
    "# For question entities - role_name is often more natural\n",
    "query_indices = action_sample[\"query_indices\"]\n",
    "for q_idx in query_indices:\n",
    "    role = action_config.entity_roles[q_idx]\n",
    "    try:\n",
    "        q_tokens = get_question_entity_token_positions(\n",
    "            action_sample, pipeline, action_config, role_name=role\n",
    "        )\n",
    "        print(f\"\\n{role.capitalize()} in question: {q_tokens}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n{role.capitalize()} not in question (expected for some query patterns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Multiple Random Examples\n",
    "\n",
    "Let's see the system work across different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating 5 random examples:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(5):\n",
    "    # Generate new sample\n",
    "    sample = sample_valid_entity_binding_input(config)\n",
    "    output = model.run_forward(sample)\n",
    "    sample[\"raw_input\"] = output[\"raw_input\"]\n",
    "\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    print(f\"Prompt: {sample['raw_input']}\")\n",
    "    print(f\"Expected answer: {output['raw_output']}\")\n",
    "\n",
    "    # Get query entity from statement and question\n",
    "    query_group = sample[\"query_group\"]\n",
    "    query_idx = sample[\"query_indices\"][0]\n",
    "    query_role = config.entity_roles[query_idx]\n",
    "\n",
    "    statement_tokens = get_entity_token_positions(\n",
    "        sample, pipeline, config, query_group, query_idx\n",
    "    )\n",
    "    print(f\"  Query entity in statement (g{query_group}_e{query_idx}): tokens {statement_tokens}\")\n",
    "\n",
    "    try:\n",
    "        question_tokens = get_question_entity_token_positions(\n",
    "            sample, pipeline, config, role_name=query_role\n",
    "        )\n",
    "        print(f\"  Query entity in question ({query_role}): tokens {question_tokens}\")\n",
    "    except ValueError:\n",
    "        print(f\"  Query entity not in question\")\n",
    "\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Template-Aware Token Positions\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Mega Template**: Combines statement and question templates with unique variable names\n",
    "   - Statement entities: `g0_e0`, `g0_e1`, `g1_e0`, `g1_e1`, ...\n",
    "   - Question entities: `person`, `food`, `query_entity`, ...\n",
    "\n",
    "2. **No Ambiguity**: Each entity position has a unique variable name, even when the same value appears multiple times\n",
    "\n",
    "3. **Flexible Indexing**: Use `token_idx` to select specific tokens within multi-token entities\n",
    "\n",
    "### API Functions:\n",
    "\n",
    "```python\n",
    "# Statement entities (by group and entity index)\n",
    "get_entity_token_positions(sample, pipeline, config, group_idx, entity_idx, token_idx=None)\n",
    "\n",
    "# Statement entities (by role name)\n",
    "get_statement_entity_token_positions(sample, pipeline, config, group_idx, role_name=\"person\")\n",
    "\n",
    "# Question entities (by role name or entity index)\n",
    "get_question_entity_token_positions(sample, pipeline, config, role_name=\"person\")\n",
    "get_question_entity_token_positions(sample, pipeline, config, entity_idx=0)\n",
    "```\n",
    "\n",
    "### For Intervention Experiments:\n",
    "\n",
    "```python\n",
    "# Get entity from statement (for testing representation)\n",
    "statement_tokens = get_entity_token_positions(sample, pipeline, config, group_idx=0, entity_idx=0)\n",
    "\n",
    "# Get entity from question (for testing retrieval)\n",
    "question_tokens = get_question_entity_token_positions(sample, pipeline, config, role_name=\"person\")\n",
    "\n",
    "# Get specific token within multi-token entity\n",
    "last_token = get_entity_token_positions(sample, pipeline, config, 0, 1, token_idx=-1)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalab (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Interchange Interventions on Positional Entity Variables\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. How interchange interventions work on the positional entity causal model\n",
    "2. The difference between causal model interventions and neural network interventions\n",
    "3. Why positional_entity variables are trivial but still useful for testing neural networks\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "The `positional_entity_g{g}_e{e}` variables in the causal model are **trivial** - they always return the group index (0 or 1). However, this doesn't mean the neural network experiment is meaningless! The neural network might store rich positional information at these token positions, even though the causal model's abstraction is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from causalab.tasks.entity_binding.config import create_sample_love_config\n",
    "from causalab.tasks.entity_binding.causal_models import create_positional_entity_causal_model\n",
    "from causalab.tasks.entity_binding.counterfactuals import swap_query_group\n",
    "from causalab.causal.counterfactual_dataset import CounterfactualDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Task Configuration and Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task configuration:\n",
      "  Max groups: 2\n",
      "  Entities per group: 2\n",
      "  Query indices: FIXED to (0,)\n",
      "\n",
      "Causal model: entity_binding_positional_entity_2g_2e\n"
     ]
    }
   ],
   "source": [
    "# Create config\n",
    "config = create_sample_love_config()\n",
    "config.max_groups = 2\n",
    "config.prompt_prefix = \"We will ask a question about the following sentences.\\n\\n\"\n",
    "config.statement_question_separator = \"\\n\\n\"\n",
    "config.prompt_suffix = \"\\nAnswer:\"\n",
    "config.fixed_query_indices = (0,)\n",
    "\n",
    "print(\"Task configuration:\")\n",
    "print(f\"  Max groups: {config.max_groups}\")\n",
    "print(f\"  Entities per group: {config.max_entities_per_group}\")\n",
    "print(f\"  Query indices: FIXED to {config.fixed_query_indices}\")\n",
    "\n",
    "# Create positional entity causal model\n",
    "causal_model = create_positional_entity_causal_model(config)\n",
    "print(f\"\\nCausal model: {causal_model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate a Counterfactual Pair\n",
    "\n",
    "We'll use `swap_query_group()` which swaps entity groups between original and counterfactual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate a counterfactual pair\nexample = swap_query_group(config)\n\ninput_sample = example[\"input\"]\ncounterfactual_sample = example[\"counterfactual_inputs\"][0]\n\nprint(\"Original input:\")\nprint(f\"  Entity g0_e0: {input_sample['entity_g0_e0']}\")\nprint(f\"  Entity g0_e1: {input_sample['entity_g0_e1']}\")\nprint(f\"  Entity g1_e0: {input_sample['entity_g1_e0']}\")\nprint(f\"  Entity g1_e1: {input_sample['entity_g1_e1']}\")\nprint(f\"  query_group: {input_sample['query_group']}\")\nprint(f\"  query_e0: {input_sample['query_e0']}, query_e1: {input_sample['query_e1']}\")\nprint(f\"  Prompt: {input_sample['raw_input']}\")\n\nprint(\"\\nCounterfactual input:\")\nprint(f\"  Entity g0_e0: {counterfactual_sample['entity_g0_e0']}\")\nprint(f\"  Entity g0_e1: {counterfactual_sample['entity_g0_e1']}\")\nprint(f\"  Entity g1_e0: {counterfactual_sample['entity_g1_e0']}\")\nprint(f\"  Entity g1_e1: {counterfactual_sample['entity_g1_e1']}\")\nprint(f\"  query_group: {counterfactual_sample['query_group']}\")\nprint(f\"  query_e0: {counterfactual_sample['query_e0']}, query_e1: {counterfactual_sample['query_e1']}\")\nprint(f\"  Prompt: {counterfactual_sample['raw_input']}\")\n\nprint(\"\\nNote: The entity groups are swapped between original and counterfactual!\")\nprint(\"The query_group and query_e{e} variables track which group/entities are being queried.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Causal Model Without Intervention\n",
    "\n",
    "First, let's see what the causal model computes for both inputs without any intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input (no intervention):\n",
      "  positional_entity_g0_e1: 0\n",
      "  positional_entity_g1_e1: 1\n",
      "  positional_answer: 1\n",
      "  raw_output: bread\n",
      "\n",
      "Counterfactual input (no intervention):\n",
      "  positional_entity_g0_e1: 0\n",
      "  positional_entity_g1_e1: 1\n",
      "  positional_answer: 0\n",
      "  raw_output: bread\n",
      "\n",
      "Observation: positional_entity variables are always 0 and 1!\n",
      "They just return the group index, regardless of what entities are in the groups.\n"
     ]
    }
   ],
   "source": [
    "# Run model on original\n",
    "print(\"Original input (no intervention):\")\n",
    "original_output = causal_model.run_forward(input_sample)\n",
    "print(f\"  positional_entity_g0_e1: {original_output['positional_entity_g0_e1']}\")\n",
    "print(f\"  positional_entity_g1_e1: {original_output['positional_entity_g1_e1']}\")\n",
    "print(f\"  positional_answer: {original_output['positional_answer']}\")\n",
    "print(f\"  raw_output: {original_output['raw_output']}\")\n",
    "\n",
    "# Run model on counterfactual\n",
    "print(\"\\nCounterfactual input (no intervention):\")\n",
    "counter_output = causal_model.run_forward(counterfactual_sample)\n",
    "print(f\"  positional_entity_g0_e1: {counter_output['positional_entity_g0_e1']}\")\n",
    "print(f\"  positional_entity_g1_e1: {counter_output['positional_entity_g1_e1']}\")\n",
    "print(f\"  positional_answer: {counter_output['positional_answer']}\")\n",
    "print(f\"  raw_output: {counter_output['raw_output']}\")\n",
    "\n",
    "print(\"\\nObservation: positional_entity variables are always 0 and 1!\")\n",
    "print(\n",
    "    \"They just return the group index, regardless of what entities are in the groups.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Perform Interchange Intervention\n",
    "\n",
    "Now we'll perform an interchange intervention using arrow syntax:\n",
    "- `positional_entity_g0_e1 <- positional_entity_g1_e1` (from counterfactual)\n",
    "- `positional_entity_g1_e1 <- positional_entity_g0_e1` (from counterfactual)\n",
    "\n",
    "This tests: \"What happens if we swap the positional entity values?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variables: ['positional_entity_g0_e1<-positional_entity_g1_e1', 'positional_entity_g1_e1<-positional_entity_g0_e1']\n",
      "\n",
      "This means:\n",
      "  - Take positional_entity_g1_e1 from counterfactual → patch into positional_entity_g0_e1 of original\n",
      "  - Take positional_entity_g0_e1 from counterfactual → patch into positional_entity_g1_e1 of original\n",
      "entity_g0_e0: Pete\n",
      "entity_g0_e1: pie\n",
      "entity_g1_e0: Ann\n",
      "entity_g1_e1: bread\n",
      "query_group: 1\n",
      "query_indices: (0,)\n",
      "answer_index: 1\n",
      "active_groups: 2\n",
      "entities_per_group: 2\n",
      "statement_template: {entity_e0} loves {entity_e1}\n",
      "positional_entity_g0_e0: 1\n",
      "positional_entity_g0_e1: 1\n",
      "positional_entity_g1_e0: 0\n",
      "positional_entity_g1_e1: 0\n",
      "question_template: What does {query_entity} love?\n",
      "positional_query_e0: (0,)\n",
      "positional_query_e1: ()\n",
      "positional_answer: 0\n",
      "raw_input: We will ask a question about the following sentences.\n",
      "\n",
      "Pete loves pie, and Ann loves bread.\n",
      "\n",
      "What does Ann love?\n",
      "Answer:\n",
      "raw_output: pie\n"
     ]
    }
   ],
   "source": [
    "# Define target variables\n",
    "target_variables = [\n",
    "    \"positional_entity_g0_e1<-positional_entity_g1_e1\",\n",
    "    \"positional_entity_g1_e1<-positional_entity_g0_e1\",\n",
    "]\n",
    "\n",
    "print(f\"Target variables: {target_variables}\")\n",
    "print(\"\\nThis means:\")\n",
    "print(\n",
    "    \"  - Take positional_entity_g1_e1 from counterfactual → patch into positional_entity_g0_e1 of original\"\n",
    ")\n",
    "print(\n",
    "    \"  - Take positional_entity_g0_e1 from counterfactual → patch into positional_entity_g1_e1 of original\"\n",
    ")\n",
    "\n",
    "# Perform interchange intervention\n",
    "intervened_output = causal_model.run_interchange(\n",
    "    input_sample,\n",
    "    {\n",
    "        \"positional_entity_g0_e1<-positional_entity_g1_e1\": counterfactual_sample,\n",
    "        \"positional_entity_g1_e1<-positional_entity_g0_e1\": counterfactual_sample,\n",
    "        \"positional_entity_g0_e0<-positional_entity_g1_e0\": counterfactual_sample,\n",
    "        \"positional_entity_g1_e0<-positional_entity_g0_e0\": counterfactual_sample,\n",
    "    },\n",
    ")\n",
    "\n",
    "for variable in intervened_output:\n",
    "    print(f\"{variable}: {intervened_output[variable]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Understanding Why the Intervention Has No Effect\n",
    "\n",
    "The positional_entity variables are **deterministic functions** that always return their group index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Understanding positional_entity variables:\")\nprint(\"\\nIn the causal model mechanism:\")\nprint(\n    \"  positional_entity_g0_e1 = lambda entity_val: 0 if entity_val is not None else None\"\n)\nprint(\n    \"  positional_entity_g1_e1 = lambda entity_val: 1 if entity_val is not None else None\"\n)\nprint(\"\\nThey ALWAYS return their group index (0 or 1)!\")\n\nprint(\"\\nKey causal model variables:\")\nprint(\"  - query_group: Which group contains the query entity (input variable)\")\nprint(\"  - query_e0, query_e1: The actual query entities from that group (input variables)\")\nprint(\"  - positional_entity_g{g}_e{e}: Group index for each entity position (trivial)\")\nprint(\"  - positional_answer: Which group to retrieve from (computed from search)\")\n\nprint(\"\\nIntervention effect on values:\")\nprint(\n    f\"  Original:   g0_e1={original_output['positional_entity_g0_e1']}, g1_e1={original_output['positional_entity_g1_e1']}\"\n)\nprint(\n    f\"  Counter:    g0_e1={counter_output['positional_entity_g0_e1']}, g1_e1={counter_output['positional_entity_g1_e1']}\"\n)\nprint(\n    f\"  Intervened: g0_e1={intervened_output['positional_entity_g0_e1']}, g1_e1={intervened_output['positional_entity_g1_e1']}\"\n)\nprint(\n    \"\\nNo change! Because both original and counterfactual have the same positional values (0, 1).\"\n)\n\n# Check downstream effects\nprint(\"\\nDownstream effects:\")\nif intervened_output[\"positional_answer\"] != original_output[\"positional_answer\"]:\n    print(\n        f\"  positional_answer changed: {original_output['positional_answer']} -> {intervened_output['positional_answer']}\"\n    )\nelse:\n    print(f\"  positional_answer unchanged: {original_output['positional_answer']}\")\n\nif intervened_output[\"raw_output\"] != original_output[\"raw_output\"]:\n    print(\n        f\"  raw_output changed: '{original_output['raw_output']}' -> '{intervened_output['raw_output']}'\"\n    )\nelse:\n    print(f\"  raw_output unchanged: '{original_output['raw_output']}'\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Distinguishability on a Dataset\n",
    "\n",
    "Let's generate a small dataset and test if the intervention is distinguishable from no intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset of 16 counterfactual pairs...\n",
      "✓ Generated 16 pairs\n",
      "\n",
      "Test 1: Can we distinguish the intervention from NO intervention?\n",
      "  Variables: ['positional_entity_g0_e1<-positional_entity_g1_e1', 'positional_entity_g1_e1<-positional_entity_g0_e1']\n",
      "  Comparing: intervention on these variables vs. None\n",
      "Can distinguish between ['positional_entity_g0_e1<-positional_entity_g1_e1', 'positional_entity_g1_e1<-positional_entity_g0_e1'] and None: 0 out of 16 examples\n",
      "Proportion of distinguishable examples: 0.00\n",
      "\n",
      "Result:\n",
      "  Distinguishable examples: 0/16\n",
      "  Proportion: 0.00%\n",
      "\n",
      "✓ As expected: 0% distinguishable!\n",
      "  The intervention has no effect because positional_entity values are always 0 and 1.\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "print(\"Generating dataset of 16 counterfactual pairs...\")\n",
    "dataset = CounterfactualDataset.from_sampler(\n",
    "    16, lambda: swap_query_group(config), id=\"swap_query_group_test\"\n",
    ")\n",
    "print(f\"✓ Generated {len(dataset)} pairs\")\n",
    "\n",
    "# Test distinguishability from no intervention\n",
    "print(\"\\nTest 1: Can we distinguish the intervention from NO intervention?\")\n",
    "print(f\"  Variables: {target_variables}\")\n",
    "print(\"  Comparing: intervention on these variables vs. None\")\n",
    "\n",
    "result = causal_model.can_distinguish_with_dataset(dataset, target_variables, None)\n",
    "\n",
    "print(\"\\nResult:\")\n",
    "print(f\"  Distinguishable examples: {result['count']}/{len(dataset)}\")\n",
    "print(f\"  Proportion: {result['proportion']:.2%}\")\n",
    "\n",
    "if result[\"proportion\"] == 0:\n",
    "    print(\"\\n✓ As expected: 0% distinguishable!\")\n",
    "    print(\n",
    "        \"  The intervention has no effect because positional_entity values are always 0 and 1.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Distinguishability from Another Variable\n",
    "\n",
    "Even though intervening on positional_entity has no effect, it should still be distinguishable from intervening on other variables like `positional_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2: Can we distinguish from positional_answer intervention?\n",
      "Can distinguish between ['positional_entity_g0_e1<-positional_entity_g1_e1', 'positional_entity_g1_e1<-positional_entity_g0_e1'] and ['positional_answer']: 16 out of 16 examples\n",
      "Proportion of distinguishable examples: 1.00\n",
      "\n",
      "Result:\n",
      "  Distinguishable examples: 16/16\n",
      "  Proportion: 100.00%\n",
      "\n",
      "✓ 100% distinguishable!\n",
      "  This confirms positional_entity and positional_answer are different variables.\n"
     ]
    }
   ],
   "source": [
    "print(\"Test 2: Can we distinguish from positional_answer intervention?\")\n",
    "\n",
    "result2 = causal_model.can_distinguish_with_dataset(\n",
    "    dataset, target_variables, [\"positional_answer\"]\n",
    ")\n",
    "\n",
    "print(\"\\nResult:\")\n",
    "print(f\"  Distinguishable examples: {result2['count']}/{len(dataset)}\")\n",
    "print(f\"  Proportion: {result2['proportion']:.2%}\")\n",
    "\n",
    "if result2[\"proportion\"] == 1.0:\n",
    "    print(\"\\n✓ 100% distinguishable!\")\n",
    "    print(\n",
    "        \"  This confirms positional_entity and positional_answer are different variables.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 1. Causal Model Behavior\n",
    "\n",
    "- **positional_entity variables are trivial**: They always return their group index (0 or 1)\n",
    "- **Interchange intervention has no effect**: Because both original and counterfactual have the same values (0, 1)\n",
    "- **0% distinguishable from no intervention**: The causal model outputs don't change\n",
    "- **100% distinguishable from positional_answer**: They are different variables in the graph\n",
    "\n",
    "### 2. Why This Still Matters for Neural Networks\n",
    "\n",
    "Even though the causal model's positional_entity variables are trivial, the neural network experiment is meaningful because:\n",
    "\n",
    "1. **The causal model is an abstraction**: It captures the logical structure, not the actual computation\n",
    "2. **Neural representations are NOT trivial**: The network might store rich positional information at the e1 token positions\n",
    "3. **The intervention tests a hypothesis**: Does the network encode \"which group this entity belongs to\" at the entity token positions?\n",
    "4. **Token positions matter**: We're intervening at specific locations (last token of e1 entities) in the neural network\n",
    "\n",
    "### 3. Causal Abstraction Claim\n",
    "\n",
    "The experiment tests whether:\n",
    "- The neural network's activations at position `[g0_e1_last_token, g1_e1_last_token]`\n",
    "- Are causally aligned with the causal model's `positional_entity_g0_e1` and `positional_entity_g1_e1` variables\n",
    "- Even though those causal variables are trivial (always 0, 1), the neural representations might be non-trivial\n",
    "- If swapping those neural representations affects retrieval, it suggests the network is encoding positional information there\n",
    "\n",
    "### 4. Experimental Design Insight\n",
    "\n",
    "This is an example of testing an **intermediate representation hypothesis**:\n",
    "- We're not testing if the network computes 0 or 1 at those positions\n",
    "- We're testing if those positions **causally influence** downstream retrieval\n",
    "- The token positions act as \"probes\" into the network's internal computations\n",
    "- Swapping representations tests if they carry information that affects the output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-abstraction (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}